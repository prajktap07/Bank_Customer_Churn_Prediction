{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82651555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13f0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df=pd.read_csv('Bank Customer Churn Prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae547b",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14514b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer id is unique for every person so this not useful in our analysis\n",
    "df.drop('customer_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82fee7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score country  gender  age  tenure    balance  products_number  \\\n",
       "0           619  France  Female   42       2       0.00                1   \n",
       "1           608   Spain  Female   41       1   83807.86                1   \n",
       "2           502  France  Female   42       8  159660.80                3   \n",
       "3           699  France  Female   39       1       0.00                2   \n",
       "4           850   Spain  Female   43       2  125510.82                1   \n",
       "\n",
       "   credit_card  active_member  estimated_salary  churn  \n",
       "0            1              1         101348.88      1  \n",
       "1            0              1         112542.58      0  \n",
       "2            1              0         113931.57      1  \n",
       "3            0              0          93826.63      0  \n",
       "4            1              1          79084.10      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de32e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split our dataframe into x-feature variable and y-target variable.\n",
    "X=df.drop('churn',axis=1) # Features (all columns except 'churn')\n",
    "Y=df['churn'] # Target variable ('churn' column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88fd020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score country  gender  age  tenure    balance  products_number  \\\n",
       "0           619  France  Female   42       2       0.00                1   \n",
       "1           608   Spain  Female   41       1   83807.86                1   \n",
       "2           502  France  Female   42       8  159660.80                3   \n",
       "3           699  France  Female   39       1       0.00                2   \n",
       "4           850   Spain  Female   43       2  125510.82                1   \n",
       "\n",
       "   credit_card  active_member  estimated_salary  \n",
       "0            1              1         101348.88  \n",
       "1            0              1         112542.58  \n",
       "2            1              0         113931.57  \n",
       "3            0              0          93826.63  \n",
       "4            1              1          79084.10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head() # preview of feature varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f1d8fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head() # preview of target varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a7dd86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_columns : ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'credit_card', 'active_member', 'estimated_salary']\n",
      "cat_columns ['country', 'gender']\n"
     ]
    }
   ],
   "source": [
    "# find list of numerical feature and categorical feature\n",
    "\n",
    "# List numerical features\n",
    "num_columns = X.select_dtypes(include='number').columns.tolist()\n",
    "print('num_columns :',num_columns)\n",
    "\n",
    "# List categorical features\n",
    "cat_columns = X.select_dtypes(include='object').columns.tolist()\n",
    "print('cat_columns',cat_columns)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d844b58f",
   "metadata": {},
   "source": [
    "#create train -test split\n",
    "\n",
    "#30% of observations will be set aside for the test set the rest, 70%, will be used as the training set\n",
    "\n",
    "# randomstate:This ensures that every time you run the code with the same random_state value, you will get the same randomized results.\n",
    "# stratify: Stratified sampling ensures that the target variable's class distribution is preserved in both the train and test sets.\n",
    "\n",
    "\n",
    "#test_size: It specifies the proportion of the data that should be allocated to the test set. In this case, it is set to 0.3, which means 30% of the data will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "681dc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state=10\n",
    "\n",
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=df.churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f964f73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 7000\n",
      "X_test: 3000\n",
      "y_train: 7000\n",
      "y_test: 3000\n"
     ]
    }
   ],
   "source": [
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print('X_train:', len(X_train))\n",
    "print('X_test:', len(X_test))\n",
    "print('y_train:', len(y_train))\n",
    "print('y_test:', len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb0c3463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 5, 6, 7, 8, 9]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "# for numerical fetures\n",
    "num_features = [] \n",
    "\n",
    "for i in num_columns:\n",
    "    location = X.columns.get_loc(i) # this give loaction/index of the current column\n",
    "    num_features.append(location)\n",
    "print(num_features)\n",
    "\n",
    "\n",
    "# for categorical features\n",
    "cat_features = []\n",
    "\n",
    "for i in cat_columns:\n",
    "    location = X.columns.get_loc(i)\n",
    "    cat_features.append(location)\n",
    "print(cat_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5e4f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                ('onehotencoder', OneHotEncoder(sparse=False),\n",
       "                                 [1, 2])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "# Need to be numeric not string to specify columns name \n",
    "preprocess = make_column_transformer(\n",
    "    (MinMaxScaler(), [0,3,4,5,6,7,8,9]),\n",
    "    (OneHotEncoder(sparse=False), [1,2])\n",
    ")\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "388c2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Function for creating model pipelines - \n",
    "from sklearn.pipeline import make_pipeline\n",
    "#foe evaluation of model --Classification metrics\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4133420",
   "metadata": {},
   "source": [
    "# FOR LOGISTIC REGRESSION MODEl.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0955dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  [0, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [1, 2])])),\n",
       "                ('logisticregression', LogisticRegression(random_state=10))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import classifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# Define model with pipeline\n",
    "Logistic_model = make_pipeline(preprocess,LogisticRegression(random_state=random_state))\n",
    "\n",
    "Logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d77b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV  # used for hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd1e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {\n",
    "    'logisticregression__C' : [0.01, 0.05, 0.1, 0.5, 1, 5],\n",
    "    'logisticregression__solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(Logistic_model, lr_param_grid, verbose=3, cv= 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a60c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__solver=liblinear;, score=0.798 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__solver=newton-cg;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__solver=newton-cg;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__solver=newton-cg;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__solver=newton-cg;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__solver=newton-cg;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__solver=sag;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__solver=sag;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__solver=sag;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__solver=sag;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__solver=sag;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.01, logisticregression__solver=saga;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.01, logisticregression__solver=saga;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.01, logisticregression__solver=saga;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.01, logisticregression__solver=saga;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.01, logisticregression__solver=saga;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.05, logisticregression__solver=liblinear;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.05, logisticregression__solver=liblinear;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.05, logisticregression__solver=liblinear;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.05, logisticregression__solver=liblinear;, score=0.809 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.05, logisticregression__solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.05, logisticregression__solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.05, logisticregression__solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.05, logisticregression__solver=newton-cg;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.05, logisticregression__solver=newton-cg;, score=0.809 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.05, logisticregression__solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.05, logisticregression__solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.05, logisticregression__solver=lbfgs;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.05, logisticregression__solver=lbfgs;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.05, logisticregression__solver=lbfgs;, score=0.809 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.05, logisticregression__solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.05, logisticregression__solver=sag;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.05, logisticregression__solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.05, logisticregression__solver=sag;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.05, logisticregression__solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.05, logisticregression__solver=sag;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.05, logisticregression__solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.05, logisticregression__solver=saga;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.05, logisticregression__solver=saga;, score=0.813 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.05, logisticregression__solver=saga;, score=0.809 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.05, logisticregression__solver=saga;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__solver=liblinear;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__solver=liblinear;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__solver=liblinear;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__solver=liblinear;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__solver=newton-cg;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__solver=newton-cg;, score=0.817 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__solver=newton-cg;, score=0.806 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__solver=newton-cg;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__solver=lbfgs;, score=0.817 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__solver=lbfgs;, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__solver=lbfgs;, score=0.806 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__solver=lbfgs;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__solver=sag;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__solver=sag;, score=0.817 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__solver=sag;, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__solver=sag;, score=0.806 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__solver=sag;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.1, logisticregression__solver=saga;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.1, logisticregression__solver=saga;, score=0.817 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.1, logisticregression__solver=saga;, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.1, logisticregression__solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.1, logisticregression__solver=saga;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.5, logisticregression__solver=liblinear;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.5, logisticregression__solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.5, logisticregression__solver=liblinear;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.5, logisticregression__solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.5, logisticregression__solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.5, logisticregression__solver=newton-cg;, score=0.812 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END logisticregression__C=0.5, logisticregression__solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.5, logisticregression__solver=newton-cg;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.5, logisticregression__solver=newton-cg;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.5, logisticregression__solver=newton-cg;, score=0.823 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.5, logisticregression__solver=lbfgs;, score=0.812 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.5, logisticregression__solver=lbfgs;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.5, logisticregression__solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.5, logisticregression__solver=lbfgs;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.5, logisticregression__solver=lbfgs;, score=0.823 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.5, logisticregression__solver=sag;, score=0.812 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.5, logisticregression__solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.5, logisticregression__solver=sag;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.5, logisticregression__solver=sag;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.5, logisticregression__solver=sag;, score=0.823 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=0.5, logisticregression__solver=saga;, score=0.812 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=0.5, logisticregression__solver=saga;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=0.5, logisticregression__solver=saga;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=0.5, logisticregression__solver=saga;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=0.5, logisticregression__solver=saga;, score=0.823 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=1, logisticregression__solver=liblinear;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=1, logisticregression__solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=1, logisticregression__solver=liblinear;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=1, logisticregression__solver=liblinear;, score=0.814 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=1, logisticregression__solver=liblinear;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=1, logisticregression__solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=1, logisticregression__solver=newton-cg;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=1, logisticregression__solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=1, logisticregression__solver=newton-cg;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=1, logisticregression__solver=newton-cg;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=1, logisticregression__solver=lbfgs;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=1, logisticregression__solver=lbfgs;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=1, logisticregression__solver=lbfgs;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=1, logisticregression__solver=lbfgs;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=1, logisticregression__solver=lbfgs;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=1, logisticregression__solver=sag;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=1, logisticregression__solver=sag;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=1, logisticregression__solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=1, logisticregression__solver=sag;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=1, logisticregression__solver=sag;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=1, logisticregression__solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=1, logisticregression__solver=saga;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=1, logisticregression__solver=saga;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=1, logisticregression__solver=saga;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=1, logisticregression__solver=saga;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=5, logisticregression__solver=liblinear;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=5, logisticregression__solver=liblinear;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=5, logisticregression__solver=liblinear;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=5, logisticregression__solver=liblinear;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=5, logisticregression__solver=liblinear;, score=0.822 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=5, logisticregression__solver=newton-cg;, score=0.808 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=5, logisticregression__solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=5, logisticregression__solver=newton-cg;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=5, logisticregression__solver=newton-cg;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=5, logisticregression__solver=newton-cg;, score=0.822 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=5, logisticregression__solver=lbfgs;, score=0.808 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=5, logisticregression__solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=5, logisticregression__solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=5, logisticregression__solver=lbfgs;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=5, logisticregression__solver=lbfgs;, score=0.822 total time=   0.0s\n",
      "[CV 1/5] END logisticregression__C=5, logisticregression__solver=sag;, score=0.808 total time=   0.0s\n",
      "[CV 2/5] END logisticregression__C=5, logisticregression__solver=sag;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END logisticregression__C=5, logisticregression__solver=sag;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END logisticregression__C=5, logisticregression__solver=sag;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=5, logisticregression__solver=sag;, score=0.822 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END logisticregression__C=5, logisticregression__solver=saga;, score=0.808 total time=   2.8s\n",
      "[CV 2/5] END logisticregression__C=5, logisticregression__solver=saga;, score=0.807 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END logisticregression__C=5, logisticregression__solver=saga;, score=0.811 total time=   0.1s\n",
      "[CV 4/5] END logisticregression__C=5, logisticregression__solver=saga;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END logisticregression__C=5, logisticregression__solver=saga;, score=0.822 total time=   0.1s\n",
      "Best Hyperparameters for logistic_reg: {'logisticregression__C': 0.1, 'logisticregression__solver': 'liblinear'}\n",
      "Best Score for logistic_reg: 0.8142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the training data\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score for Lr\n",
    "best_params = lr_grid.best_params_\n",
    "best_score = lr_grid.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7870838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for logistic_reg: {'logisticregression__C': 0.1, 'logisticregression__solver': 'liblinear'}\n",
      "Best Score for logistic_reg: 0.8142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters for logistic_reg:\", best_params)\n",
    "print(\"Best Score for logistic_reg:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7410657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8138571428571428\n",
      "Testing Data Score: 0.8086666666666666\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {lr_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_grid.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2848a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator to make predictions on new data (X_test)\n",
    "y_pred = lr_grid.best_estimator_.predict(X_test)\n",
    "#if you give only best_params:AttributeError: 'dict' object has no attribute 'predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8edfc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89      2389\n",
      "           1       0.65      0.13      0.22       611\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.73      0.56      0.56      3000\n",
      "weighted avg       0.78      0.81      0.75      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "classification_rep_lr = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bf15d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2345   44]\n",
      " [ 530   81]]\n"
     ]
    }
   ],
   "source": [
    " # Calculate the confusion matrix\n",
    "confusion_mat_lr = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed95230",
   "metadata": {},
   "source": [
    "# FOR SVC MODEL.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26c42a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 2/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 4/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.3s\n",
      "[CV 5/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 2/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 3/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 4/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   0.8s\n",
      "[CV 5/5] END svc__C=0.01, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 1/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 2/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 3/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 4/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 5/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 2/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 3/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.8s\n",
      "[CV 4/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 5/5] END svc__C=0.01, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 1/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 2/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.3s\n",
      "[CV 3/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 4/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 5/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 2/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   1.1s\n",
      "[CV 3/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 4/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 5/5] END svc__C=0.1, svc__gamma=scale, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 1/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 2/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 3/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 4/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 5/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 2/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 3/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 4/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 5/5] END svc__C=0.1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 1/5] END svc__C=1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 2/5] END svc__C=1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 3/5] END svc__C=1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 4/5] END svc__C=1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 5/5] END svc__C=1, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END svc__C=1, svc__gamma=scale, svc__kernel=rbf;, score=0.828 total time=   1.0s\n",
      "[CV 2/5] END svc__C=1, svc__gamma=scale, svc__kernel=rbf;, score=0.832 total time=   1.0s\n",
      "[CV 3/5] END svc__C=1, svc__gamma=scale, svc__kernel=rbf;, score=0.835 total time=   0.9s\n",
      "[CV 4/5] END svc__C=1, svc__gamma=scale, svc__kernel=rbf;, score=0.830 total time=   0.9s\n",
      "[CV 5/5] END svc__C=1, svc__gamma=scale, svc__kernel=rbf;, score=0.839 total time=   1.0s\n",
      "[CV 1/5] END svc__C=1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END svc__C=1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 3/5] END svc__C=1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 4/5] END svc__C=1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 5/5] END svc__C=1, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END svc__C=1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 2/5] END svc__C=1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 3/5] END svc__C=1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 4/5] END svc__C=1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 5/5] END svc__C=1, svc__gamma=auto, svc__kernel=rbf;, score=0.796 total time=   1.0s\n",
      "[CV 1/5] END svc__C=10, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END svc__C=10, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.6s\n",
      "[CV 3/5] END svc__C=10, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 4/5] END svc__C=10, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.7s\n",
      "[CV 5/5] END svc__C=10, svc__gamma=scale, svc__kernel=linear;, score=0.796 total time=   0.6s\n",
      "[CV 1/5] END svc__C=10, svc__gamma=scale, svc__kernel=rbf;, score=0.851 total time=   1.1s\n",
      "[CV 2/5] END svc__C=10, svc__gamma=scale, svc__kernel=rbf;, score=0.844 total time=   1.0s\n",
      "[CV 3/5] END svc__C=10, svc__gamma=scale, svc__kernel=rbf;, score=0.845 total time=   1.1s\n",
      "[CV 4/5] END svc__C=10, svc__gamma=scale, svc__kernel=rbf;, score=0.851 total time=   1.1s\n",
      "[CV 5/5] END svc__C=10, svc__gamma=scale, svc__kernel=rbf;, score=0.856 total time=   1.1s\n",
      "[CV 1/5] END svc__C=10, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 2/5] END svc__C=10, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 3/5] END svc__C=10, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.6s\n",
      "[CV 4/5] END svc__C=10, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.5s\n",
      "[CV 5/5] END svc__C=10, svc__gamma=auto, svc__kernel=linear;, score=0.796 total time=   0.4s\n",
      "[CV 1/5] END svc__C=10, svc__gamma=auto, svc__kernel=rbf;, score=0.831 total time=   0.9s\n",
      "[CV 2/5] END svc__C=10, svc__gamma=auto, svc__kernel=rbf;, score=0.835 total time=   1.0s\n",
      "[CV 3/5] END svc__C=10, svc__gamma=auto, svc__kernel=rbf;, score=0.835 total time=   0.9s\n",
      "[CV 4/5] END svc__C=10, svc__gamma=auto, svc__kernel=rbf;, score=0.833 total time=   0.9s\n",
      "[CV 5/5] END svc__C=10, svc__gamma=auto, svc__kernel=rbf;, score=0.845 total time=   1.1s\n",
      "Best Hyperparameters for SVC: {'svc__C': 10, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
      "Best Score for SVC: 0.8492857142857144\n",
      "Training Data Score: 0.8641428571428571\n",
      "Testing Data Score: 0.8583333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the pipeline\n",
    "SVC_model = make_pipeline(preprocess, SVC(random_state=random_state))\n",
    "\n",
    "# Define the parameter grid\n",
    "svc_param_grid = {\n",
    "    'svc__C': [0.01, 0.1, 1, 10],\n",
    "    'svc__kernel': ['linear', 'rbf'],\n",
    "    'svc__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "svc_grid = GridSearchCV(SVC_model, svc_param_grid, verbose=3, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score for SVC\n",
    "best_params = svc_grid.best_params_\n",
    "best_score = svc_grid.best_score_\n",
    "print(\"Best Hyperparameters for SVC:\", best_params)\n",
    "print(\"Best Score for SVC:\", best_score)\n",
    "\n",
    "print(f\"Training Data Score: {svc_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {svc_grid.score(X_test, y_test)}\")\n",
    "\n",
    "# Use the best estimator to make predictions on new data (X_test)\n",
    "y_pred = svc_grid.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e9d43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92      2389\n",
      "           1       0.82      0.39      0.53       611\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.84      0.68      0.72      3000\n",
      "weighted avg       0.85      0.86      0.84      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "\n",
    "classification_rep_svc = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71f06988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2337   52]\n",
      " [ 373  238]]\n"
     ]
    }
   ],
   "source": [
    " # Calculate the confusion matrix\n",
    "confusion_mat_svc = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a2d46",
   "metadata": {},
   "source": [
    "# FOR RANDOM_FOREST MODEL.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "451077a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.859 total time=   0.5s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.850 total time=   0.5s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.858 total time=   0.5s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.851 total time=   0.5s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.862 total time=   0.6s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.856 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.853 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.858 total time=   1.1s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.858 total time=   1.4s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.864 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.6s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.854 total time=   2.0s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.861 total time=   2.0s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.8s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.866 total time=   1.7s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.860 total time=   0.5s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.856 total time=   0.5s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.859 total time=   0.6s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.864 total time=   0.5s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.859 total time=   0.5s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.859 total time=   1.0s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.857 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.859 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.860 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.864 total time=   1.1s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.6s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.856 total time=   1.6s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.5s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.859 total time=   1.5s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.863 total time=   1.5s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.858 total time=   0.4s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.855 total time=   0.4s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.864 total time=   0.4s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.861 total time=   0.4s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.866 total time=   0.5s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.858 total time=   1.1s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.854 total time=   0.9s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.859 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.864 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.863 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.4s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.858 total time=   1.4s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.4s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.5s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=None, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.864 total time=   1.3s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.850 total time=   0.2s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.841 total time=   0.2s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.846 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.849 total time=   0.3s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.850 total time=   0.3s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.851 total time=   0.5s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.846 total time=   0.5s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.851 total time=   0.5s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.849 total time=   0.6s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.849 total time=   0.7s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.849 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.846 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.851 total time=   1.0s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.846 total time=   0.8s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.852 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.844 total time=   0.2s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.841 total time=   0.2s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.845 total time=   0.3s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.850 total time=   0.2s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.851 total time=   0.2s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.850 total time=   0.6s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.849 total time=   0.6s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.850 total time=   0.5s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.851 total time=   0.5s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.849 total time=   0.6s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.851 total time=   0.8s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.847 total time=   0.8s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.850 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.850 total time=   0.7s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.851 total time=   0.8s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.844 total time=   0.2s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.837 total time=   0.3s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.846 total time=   0.3s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.849 total time=   0.3s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.849 total time=   0.2s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.847 total time=   0.5s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.849 total time=   0.5s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.851 total time=   0.6s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.851 total time=   0.6s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.849 total time=   0.6s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.848 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.847 total time=   0.8s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.850 total time=   0.8s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.844 total time=   0.8s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=5, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.851 total time=   0.8s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.854 total time=   0.4s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.860 total time=   0.4s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.861 total time=   0.4s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.856 total time=   0.4s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=100;, score=0.866 total time=   0.4s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.856 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.862 total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.860 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.857 total time=   1.0s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=200;, score=0.867 total time=   0.8s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.855 total time=   1.2s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.865 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.863 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.858 total time=   1.6s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=2, randomforestclassifier__n_estimators=300;, score=0.865 total time=   1.8s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.857 total time=   0.5s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.861 total time=   0.5s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.860 total time=   0.5s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.860 total time=   0.5s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=100;, score=0.866 total time=   0.4s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.859 total time=   0.9s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.863 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.861 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.864 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=200;, score=0.866 total time=   0.8s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.857 total time=   1.4s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.863 total time=   1.2s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.861 total time=   1.2s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.862 total time=   1.3s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=5, randomforestclassifier__n_estimators=300;, score=0.869 total time=   1.3s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.858 total time=   0.5s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.862 total time=   0.4s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.860 total time=   0.4s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.858 total time=   0.4s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=100;, score=0.866 total time=   0.5s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.856 total time=   0.8s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.858 total time=   1.0s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.861 total time=   0.9s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.859 total time=   0.9s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=200;, score=0.865 total time=   0.9s\n",
      "[CV 1/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.856 total time=   1.5s\n",
      "[CV 2/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.860 total time=   1.4s\n",
      "[CV 3/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.862 total time=   1.8s\n",
      "[CV 4/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.858 total time=   1.5s\n",
      "[CV 5/5] END randomforestclassifier__max_depth=10, randomforestclassifier__min_samples_split=10, randomforestclassifier__n_estimators=300;, score=0.864 total time=   1.5s\n",
      "Best Hyperparameters for Random Forest: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 200}\n",
      "Best Score for Random Forest: 0.8624285714285713\n",
      "Training Data Score: 0.9002857142857142\n",
      "Testing Data Score: 0.864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "RF_model = make_pipeline(preprocess, RandomForestClassifier(random_state=random_state))\n",
    "\n",
    "# Define the parameter grid\n",
    "rf_param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None, 5, 10],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "rf_grid = GridSearchCV(RF_model, rf_param_grid, verbose=3, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score for Random Forest\n",
    "best_params = rf_grid.best_params_\n",
    "best_score = rf_grid.best_score_\n",
    "print(\"Best Hyperparameters for Random Forest:\", best_params)\n",
    "print(\"Best Score for Random Forest:\", best_score)\n",
    "\n",
    "print(f\"Training Data Score: {rf_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_grid.score(X_test, y_test)}\")\n",
    "\n",
    "# Use the best estimator to make predictions on new data (X_test)\n",
    "y_pred = rf_grid.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "921b2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      2389\n",
      "           1       0.80      0.44      0.57       611\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.84      0.71      0.74      3000\n",
      "weighted avg       0.86      0.86      0.85      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "\n",
    "classification_rep_RF = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1906ed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2324   65]\n",
      " [ 343  268]]\n"
     ]
    }
   ],
   "source": [
    " # Calculate the confusion matrix\n",
    "confusion_mat_RF = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812d7ce",
   "metadata": {},
   "source": [
    "# FOR DECISON_TREE_MODEL..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd608f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=2;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=2;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=2;, score=0.784 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=2;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=2;, score=0.809 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=5;, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=5;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=5;, score=0.794 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=5;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=5;, score=0.815 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=10;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=10;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=10;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=10;, score=0.813 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=None, decisiontreeclassifier__min_samples_split=10;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=2;, score=0.852 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=2;, score=0.851 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=2;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=2;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=2;, score=0.853 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=5;, score=0.852 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=5;, score=0.851 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=5;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=5;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=5;, score=0.853 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=10;, score=0.852 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=10;, score=0.851 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=10;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=10;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=5, decisiontreeclassifier__min_samples_split=10;, score=0.853 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=2;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=2;, score=0.834 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=2;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=2;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=2;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=5;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=5;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=5;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=5;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=5;, score=0.854 total time=   0.0s\n",
      "[CV 1/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=10;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=10;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=10;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=10;, score=0.834 total time=   0.0s\n",
      "[CV 5/5] END decisiontreeclassifier__max_depth=10, decisiontreeclassifier__min_samples_split=10;, score=0.861 total time=   0.0s\n",
      "Best Hyperparameters for Decision Tree: {'decisiontreeclassifier__max_depth': 5, 'decisiontreeclassifier__min_samples_split': 5}\n",
      "Best Score for Decision Tree: 0.8537142857142858\n",
      "Training Data Score: 0.8578571428571429\n",
      "Testing Data Score: 0.854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the pipeline\n",
    "DT_model = make_pipeline(preprocess, DecisionTreeClassifier(random_state=random_state))\n",
    "\n",
    "# Define the parameter grid\n",
    "dt_param_grid = {\n",
    "    'decisiontreeclassifier__max_depth': [None, 5, 10],\n",
    "    'decisiontreeclassifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "dt_grid = GridSearchCV(DT_model, dt_param_grid, verbose=3, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score for Decision Tree\n",
    "best_params = dt_grid.best_params_\n",
    "best_score = dt_grid.best_score_\n",
    "print(\"Best Hyperparameters for Decision Tree:\", best_params)\n",
    "print(\"Best Score for Decision Tree:\", best_score)\n",
    "\n",
    "print(f\"Training Data Score: {dt_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {dt_grid.score(X_test, y_test)}\")\n",
    "\n",
    "# Use the best estimator to make predictions on new data (X_test)\n",
    "y_pred = dt_grid.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "487c9119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      2389\n",
      "           1       0.84      0.35      0.49       611\n",
      "\n",
      "    accuracy                           0.85      3000\n",
      "   macro avg       0.85      0.67      0.70      3000\n",
      "weighted avg       0.85      0.85      0.83      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "\n",
    "classification_rep_DT = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a796737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2350   39]\n",
      " [ 399  212]]\n"
     ]
    }
   ],
   "source": [
    " # Calculate the confusion matrix\n",
    "confusion_mat_DT = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757b317",
   "metadata": {},
   "source": [
    "# FOR KNN_MODEL.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97440f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.804 total time=   0.1s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.796 total time=   0.1s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.791 total time=   0.0s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=uniform;, score=0.806 total time=   0.0s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.795 total time=   0.0s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.809 total time=   0.0s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.793 total time=   0.0s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=3, kneighborsclassifier__weights=distance;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.806 total time=   0.0s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=uniform;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.819 total time=   0.0s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.809 total time=   0.1s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=5, kneighborsclassifier__weights=distance;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.821 total time=   0.1s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.813 total time=   0.1s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=uniform;, score=0.815 total time=   0.0s\n",
      "[CV 1/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END kneighborsclassifier__n_neighbors=7, kneighborsclassifier__weights=distance;, score=0.811 total time=   0.0s\n",
      "Best Hyperparameters for KNN: {'kneighborsclassifier__n_neighbors': 7, 'kneighborsclassifier__weights': 'distance'}\n",
      "Best Score for KNN: 0.8177142857142856\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "KNN_model = make_pipeline(preprocess, KNeighborsClassifier())\n",
    "\n",
    "# Define the parameter grid\n",
    "knn_param_grid = {\n",
    "    'kneighborsclassifier__n_neighbors': [3, 5, 7],\n",
    "    'kneighborsclassifier__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "knn_grid = GridSearchCV(KNN_model, knn_param_grid, verbose=3, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score for KNN\n",
    "best_params = knn_grid.best_params_\n",
    "best_score = knn_grid.best_score_\n",
    "print(\"Best Hyperparameters for KNN:\", best_params)\n",
    "print(\"Best Score for KNN:\", best_score)\n",
    "\n",
    "print(f\"Training Data Score: {knn_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {knn_grid.score(X_test, y_test)}\")\n",
    "\n",
    "# Use the best estimator to make predictions on new data (X_test)\n",
    "y_pred = knn_grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee86a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      2389\n",
      "           1       0.58      0.28      0.38       611\n",
      "\n",
      "    accuracy                           0.81      3000\n",
      "   macro avg       0.71      0.61      0.63      3000\n",
      "weighted avg       0.78      0.81      0.79      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "\n",
    "classification_rep_KNN = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87ade812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2265  124]\n",
      " [ 440  171]]\n"
     ]
    }
   ],
   "source": [
    " # Calculate the confusion matrix\n",
    "confusion_mat_KNN = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae9879",
   "metadata": {},
   "source": [
    "# FOR GradientBoostingClassifier MODEL.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a98813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.841 total time=   0.7s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.835 total time=   0.6s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.846 total time=   0.7s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.850 total time=   0.6s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.844 total time=   0.6s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.851 total time=   1.3s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.854 total time=   1.3s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.861 total time=   1.2s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.857 total time=   1.2s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.859 total time=   1.2s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.854 total time=   1.8s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.854 total time=   1.9s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.866 total time=   1.9s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.859 total time=   2.0s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.867 total time=   1.9s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.849 total time=   1.0s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.848 total time=   1.0s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.861 total time=   1.0s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.854 total time=   1.1s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.854 total time=   1.0s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.854 total time=   2.2s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.854 total time=   2.1s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.866 total time=   2.1s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.859 total time=   2.1s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.865 total time=   2.0s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.856 total time=   3.1s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.863 total time=   3.3s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.864 total time=   3.7s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.864 total time=   3.6s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.869 total time=   3.3s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.849 total time=   1.5s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.854 total time=   1.5s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.855 total time=   1.7s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.853 total time=   1.7s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.854 total time=   1.6s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.849 total time=   3.5s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.860 total time=   3.3s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.862 total time=   3.6s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.856 total time=   3.6s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.866 total time=   3.3s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.852 total time=   5.0s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.856 total time=   4.6s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.858 total time=   4.8s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.858 total time=   4.8s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.01, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.865 total time=   4.7s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.857 total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.856 total time=   0.7s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.866 total time=   0.7s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.873 total time=   0.8s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.869 total time=   0.6s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.860 total time=   1.5s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.856 total time=   1.7s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.860 total time=   1.4s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.866 total time=   1.5s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.863 total time=   1.7s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.861 total time=   2.2s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.859 total time=   2.5s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.857 total time=   2.0s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.866 total time=   2.0s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.861 total time=   2.3s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.848 total time=   1.0s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.862 total time=   1.0s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.861 total time=   1.1s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.862 total time=   1.2s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.864 total time=   1.2s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.856 total time=   2.2s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.859 total time=   2.4s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.861 total time=   2.2s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.851 total time=   1.9s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.859 total time=   1.9s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.846 total time=   3.2s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.857 total time=   3.3s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.860 total time=   3.0s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.846 total time=   3.2s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.861 total time=   3.0s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.853 total time=   1.5s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.851 total time=   1.4s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.854 total time=   1.7s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.854 total time=   1.5s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.860 total time=   1.6s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.852 total time=   3.2s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.853 total time=   3.2s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.853 total time=   3.1s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.853 total time=   3.1s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.859 total time=   3.0s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.849 total time=   4.7s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.854 total time=   4.9s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.856 total time=   4.5s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.850 total time=   4.8s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=0.1, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.856 total time=   4.6s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.834 total time=   0.5s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.826 total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.824 total time=   0.5s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.849 total time=   0.6s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=100;, score=0.851 total time=   0.6s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.824 total time=   1.3s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.812 total time=   1.2s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.821 total time=   1.5s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.829 total time=   1.2s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=200;, score=0.837 total time=   1.4s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.824 total time=   1.9s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.821 total time=   1.8s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.820 total time=   2.1s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.831 total time=   2.0s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=3, gradientboostingclassifier__n_estimators=300;, score=0.839 total time=   2.0s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.831 total time=   1.0s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.832 total time=   0.9s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.821 total time=   1.0s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.827 total time=   1.0s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=100;, score=0.836 total time=   0.9s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.845 total time=   2.0s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.836 total time=   1.9s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.829 total time=   2.0s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.827 total time=   2.0s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=200;, score=0.845 total time=   2.0s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.845 total time=   3.1s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.845 total time=   3.0s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.829 total time=   3.0s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.829 total time=   3.5s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=5, gradientboostingclassifier__n_estimators=300;, score=0.846 total time=   3.3s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.838 total time=   1.5s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.828 total time=   1.5s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.839 total time=   1.5s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.829 total time=   1.5s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=100;, score=0.836 total time=   1.5s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.845 total time=   3.4s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.840 total time=   3.3s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.844 total time=   3.1s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.836 total time=   3.3s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=200;, score=0.839 total time=   3.0s\n",
      "[CV 1/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.846 total time=   4.6s\n",
      "[CV 2/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.842 total time=   5.1s\n",
      "[CV 3/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.839 total time=   5.1s\n",
      "[CV 4/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.840 total time=   4.9s\n",
      "[CV 5/5] END gradientboostingclassifier__learning_rate=1.0, gradientboostingclassifier__max_depth=7, gradientboostingclassifier__n_estimators=300;, score=0.848 total time=   5.1s\n",
      "Best Hyperparameters for Gradient Boosting: {'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__n_estimators': 100}\n",
      "Best Score for Gradient Boosting: 0.8641428571428571\n",
      "Training Data Score: 0.8761428571428571\n",
      "Testing Data Score: 0.864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "GB_model = make_pipeline(preprocess, GradientBoostingClassifier(random_state=random_state))\n",
    "\n",
    "# Define the parameter grid\n",
    "gb_param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 200, 300],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'gradientboostingclassifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "gb_grid = GridSearchCV(GB_model, gb_param_grid, verbose=3, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score for Gradient Boosting\n",
    "best_params = gb_grid.best_params_\n",
    "best_score = gb_grid.best_score_\n",
    "print(\"Best Hyperparameters for Gradient Boosting:\", best_params)\n",
    "print(\"Best Score for Gradient Boosting:\", best_score)\n",
    "\n",
    "print(f\"Training Data Score: {gb_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {gb_grid.score(X_test, y_test)}\")\n",
    "\n",
    "# Use the best estimator to make predictions on new data (X_test)\n",
    "y_pred = gb_grid.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "969ebc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      2389\n",
      "           1       0.78      0.46      0.58       611\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.83      0.71      0.75      3000\n",
      "weighted avg       0.86      0.86      0.85      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "\n",
    "classification_rep_GB = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1b94ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2312   77]\n",
      " [ 331  280]]\n"
     ]
    }
   ],
   "source": [
    " # Calculate the confusion matrix\n",
    "confusion_mat_GB = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b2e2d",
   "metadata": {},
   "source": [
    "# FOR XGB MODEL.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c1d9596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.849 total time=   0.0s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.853 total time=   0.1s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.851 total time=   0.2s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.857 total time=   0.2s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.856 total time=   0.2s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.866 total time=   0.2s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.858 total time=   0.3s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.856 total time=   0.3s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.861 total time=   0.3s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.857 total time=   0.3s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.871 total time=   0.3s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.852 total time=   0.1s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.855 total time=   0.1s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.860 total time=   0.1s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.859 total time=   0.1s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.866 total time=   0.1s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.851 total time=   0.3s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.860 total time=   0.3s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.866 total time=   0.3s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.868 total time=   0.4s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.867 total time=   0.4s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.854 total time=   0.5s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.859 total time=   0.5s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.863 total time=   0.5s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.867 total time=   0.5s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.867 total time=   0.5s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.856 total time=   0.2s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.861 total time=   0.2s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.859 total time=   0.2s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.870 total time=   0.2s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.858 total time=   0.5s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.860 total time=   0.5s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.859 total time=   0.5s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.858 total time=   0.5s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.871 total time=   0.5s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.860 total time=   0.8s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.859 total time=   0.8s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.862 total time=   0.8s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.863 total time=   0.9s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.868 total time=   0.8s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.862 total time=   0.1s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.856 total time=   0.1s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.865 total time=   0.1s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.869 total time=   0.1s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.875 total time=   0.1s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.858 total time=   0.2s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.861 total time=   0.2s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.865 total time=   0.2s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.871 total time=   0.2s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.861 total time=   0.4s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.856 total time=   0.4s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.861 total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.863 total time=   0.3s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.869 total time=   0.3s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.854 total time=   0.2s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.859 total time=   0.1s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.864 total time=   0.2s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.866 total time=   0.1s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.870 total time=   0.1s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.855 total time=   0.3s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.863 total time=   0.4s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.860 total time=   0.3s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.861 total time=   0.4s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.864 total time=   0.4s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.859 total time=   0.6s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.855 total time=   0.6s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.860 total time=   0.6s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.851 total time=   0.6s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.862 total time=   0.6s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.854 total time=   0.2s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.858 total time=   0.2s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.858 total time=   0.2s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.854 total time=   0.6s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.849 total time=   0.6s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.856 total time=   0.6s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.859 total time=   0.6s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.859 total time=   0.6s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.860 total time=   0.9s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.850 total time=   0.9s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.857 total time=   1.1s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.856 total time=   0.9s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.859 total time=   0.9s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.843 total time=   0.1s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.843 total time=   0.1s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.844 total time=   0.1s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.835 total time=   0.1s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=100;, score=0.839 total time=   0.1s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.846 total time=   0.3s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.831 total time=   0.2s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.834 total time=   0.2s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=200;, score=0.826 total time=   0.2s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.836 total time=   0.4s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.836 total time=   0.4s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.839 total time=   0.4s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.830 total time=   0.4s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=3, xgbclassifier__n_estimators=300;, score=0.828 total time=   0.4s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.834 total time=   0.2s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.835 total time=   0.2s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.841 total time=   0.2s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.827 total time=   0.2s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=100;, score=0.837 total time=   0.2s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.831 total time=   0.5s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.836 total time=   0.5s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.839 total time=   0.4s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.831 total time=   0.4s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=200;, score=0.839 total time=   0.4s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.835 total time=   0.6s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.840 total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.843 total time=   0.6s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.828 total time=   0.6s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=5, xgbclassifier__n_estimators=300;, score=0.839 total time=   0.6s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.842 total time=   0.3s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.838 total time=   0.3s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.841 total time=   0.3s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.834 total time=   0.2s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=100;, score=0.835 total time=   0.2s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.841 total time=   0.5s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.839 total time=   0.5s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.845 total time=   0.5s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.833 total time=   0.5s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=200;, score=0.829 total time=   0.5s\n",
      "[CV 1/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.844 total time=   0.7s\n",
      "[CV 2/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.841 total time=   0.7s\n",
      "[CV 3/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.843 total time=   0.7s\n",
      "[CV 4/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.832 total time=   0.7s\n",
      "[CV 5/5] END xgbclassifier__learning_rate=1.0, xgbclassifier__max_depth=7, xgbclassifier__n_estimators=300;, score=0.834 total time=   0.7s\n",
      "Best Hyperparameters for XGBoost: {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 100}\n",
      "Best Score for XGBoost: 0.8652857142857142\n",
      "Training Data Score: 0.8725714285714286\n",
      "Testing Data Score: 0.8646666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "XGB_model = make_pipeline(preprocess, XGBClassifier(random_state=random_state))\n",
    "\n",
    "# Define the parameter grid\n",
    "xgb_param_grid = {\n",
    "    'xgbclassifier__n_estimators': [100, 200, 300],\n",
    "    'xgbclassifier__learning_rate': [0.01, 0.1, 1.0],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "xgb_grid = GridSearchCV(XGB_model, xgb_param_grid, verbose=3, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and best score for XGBoost\n",
    "best_params = xgb_grid.best_params_\n",
    "best_score = xgb_grid.best_score_\n",
    "print(\"Best Hyperparameters for XGBoost:\", best_params)\n",
    "print(\"Best Score for XGBoost:\", best_score)\n",
    "\n",
    "print(f\"Training Data Score: {xgb_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {xgb_grid.score(X_test, y_test)}\")\n",
    "\n",
    "# Use the best estimator to make predictions on new data (X_test)\n",
    "y_pred = xgb_grid.best_estimator_.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf39ebca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      2389\n",
      "           1       0.80      0.45      0.57       611\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.84      0.71      0.75      3000\n",
      "weighted avg       0.86      0.86      0.85      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "\n",
    "classification_rep_XGB = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d94d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2320   69]\n",
      " [ 337  274]]\n"
     ]
    }
   ],
   "source": [
    " # Calculate the confusion matrix\n",
    "confusion_mat_XGB = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat_XGB)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73f07268",
   "metadata": {},
   "source": [
    "#SUMMARY FOR ALL THE MODELS>...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest (RF): It has the highest precision, recall, and F1-score for class 1, along with a high accuracy.\n",
    "Gradient Boosting (GB) and XGBoost (XGB): Both models have comparable performance with good precision, recall, and F1-scores for class 1.\n",
    "\n",
    "#Support Vector Classifier (SVC): It also performs well with a balanced precision, recall, and F1-score for both classes.\n",
    "\n",
    "#Decision Tree (DT): It has decent performance but relatively lower recall and F1-score for class 1 compared to the top models.\n",
    "\n",
    "#Logistic Regression (LR) and K-Nearest Neighbors (KNN): Both models have relatively lower performance metrics compared to the other models.\n",
    "\n",
    "best model:\n",
    "\n",
    "Random Forest (RF) seems to be the best choice among the given models, as it achieves high precision, recall, and F1-scores for class 1, along with a high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce562dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize best model report \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the metrics from the classification report\n",
    "precision = [0.87, 0.80]\n",
    "recall = [0.97, 0.44]\n",
    "f1_score = [0.92, 0.57]\n",
    "class_labels = ['Class 0', 'Class 1']\n",
    "\n",
    "# Plot precision\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(class_labels, precision,color=['red','green'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision per Class')\n",
    "plt.show()\n",
    "\n",
    "# Plot recall\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(class_labels, recall,color=['yellow','violet'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall per Class')\n",
    "plt.show()\n",
    "\n",
    "# Plot F1-score\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(class_labels, f1_score,color=['E75480','green'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score per Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255aea4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
